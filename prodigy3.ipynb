{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvjDZnViqTDtoWvTQbP2RY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyamalviya92-pixel/prodigytask3/blob/main/prodigy3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!pip install markovify\n",
        "!pip install -m spacy download en"
      ],
      "metadata": {
        "id": "MGLioU11VPon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "import markovify\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('gutenberg')\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "7DulHuCjVf6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect Gutenberg corpus\n",
        "print(gutenberg.fileids())"
      ],
      "metadata": {
        "id": "tRnyF-ILWzPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import novels as text objects\n",
        "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
        "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
        "#print first 100 characters of each\n",
        "print('nRaw:n', hamlet[:100])\n",
        "print('nRaw:n', macbeth[:100])\n",
        "print('nRaw:n', caesar[:100])"
      ],
      "metadata": {
        "id": "OyotTowJW7md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utility function for text cleaning\n",
        "def text_cleaner(text):\n",
        "  text = re.sub(r'--', ' ', text)\n",
        "  text = re.sub('[[].*?[]]', '', text)\n",
        "  text = re.sub(r'(b|s+-?|^-?)(d+|d*.d+)b','', text)\n",
        "  text = ' '.join(text.split())\n",
        "  return text"
      ],
      "metadata": {
        "id": "A4xGgfblXabp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove chapter indicator\n",
        "hamlet = re.sub(r'Chapter d+', '', hamlet)\n",
        "macbeth = re.sub(r'Chapter d+', '', macbeth)\n",
        "caesar = re.sub(r'Chapter d+', '', caesar)\n",
        "#apply cleaning function to corpus\n",
        "hamlet = text_cleaner(hamlet)\n",
        "caesar = text_cleaner(caesar)\n",
        "macbeth = text_cleaner(macbeth)"
      ],
      "metadata": {
        "id": "JExwuRKeXi04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parse cleaned novels\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "hamlet_doc = nlp(hamlet)\n",
        "macbeth_doc = nlp(macbeth)\n",
        "caesar_doc = nlp(caesar)"
      ],
      "metadata": {
        "id": "46WDqcRBXwdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hamlet_sents = ' '.join([sent.text for sent in hamlet_doc.sents if len(sent.text) > 1])\n",
        "macbeth_sents = ' '.join([sent.text for sent in macbeth_doc.sents if len(sent.text) > 1])\n",
        "caesar_sents = ' '.join([sent.text for sent in caesar_doc.sents if len(sent.text) > 1])\n",
        "shakespeare_sents = hamlet_sents + macbeth_sents + caesar_sents\n",
        "#inspect our text\n",
        "print(shakespeare_sents)"
      ],
      "metadata": {
        "id": "cc1u2ggRYFOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create text generator using markovify\n",
        "generator_1 = markovify.Text(shakespeare_sents, state_size=3)"
      ],
      "metadata": {
        "id": "3NxTu_r1YSbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will randomly generate three sentences\n",
        "for i in range(3):\n",
        "  print(generator_1.make_sentence())\n",
        "#We will randomly generate three more sentences of no more than 100 characters\n",
        "for i in range(3):\n",
        "  print(generator_1.make_short_sentence(max_chars=100))"
      ],
      "metadata": {
        "id": "hV8bnsWHYcB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#next we will use spacy's part of speech to generate more legible text\n",
        "class POSifiedText(markovify.Text):\n",
        "   def word_split(self, sentence):\n",
        "      return ['::'.join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
        "   def word_join(self, words):\n",
        "      sentence = ' '.join(word.split('::')[0] for word in words)\n",
        "      return sentence\n",
        "#Call the class on our text\n",
        "generator_2 = POSifiedText(shakespeare_sents, state_size=3)\n",
        "# And finally, print more sentences using our new generator.\n",
        "\n",
        "#now we will use the above generator to generate sentences\n",
        "for i in range(5):\n",
        "  print(generator_2.make_sentence())\n",
        "#print 100 characters or less sentences\n",
        "for i in range(5):\n",
        "  print(generator_2.make_short_sentence(max_chars=100))"
      ],
      "metadata": {
        "id": "Gr8eQtGYYmXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}